{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lyzbdeoNVB7V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import importlib as imp\n",
        "\n",
        "import src\n",
        "import trecs\n",
        "from trecs.models import ContentFiltering\n",
        "from trecs.metrics import MSEMeasurement, InteractionSpread, InteractionSpread, InteractionSimilarity, RecSimilarity, RMSEMeasurement, InteractionMeasurement\n",
        "\n",
        "random_state = np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings_df = pd.read_csv('data/ml-100k/u.data', \n",
        "                 sep=\"\\t\", \n",
        "                 names=['UserID', 'MovieID', 'Rating', 'Timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating RecommenderSystem on MovieLens "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "binary_ratings_df = ratings_df.drop(columns=['Timestamp'])\n",
        "binary_ratings_df.loc[binary_ratings_df['Rating'] > 0, 'Rating'] = 1\n",
        "\n",
        "# turn dataframe into matrix where each movie is a column and each user is a row\n",
        "binary_ratings_matrix = binary_ratings_df.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jannik\\anaconda3\\envs\\rsenv\\lib\\site-packages\\lightfm\\_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
            "  \"LightFM was compiled without OpenMP support. \"\n"
          ]
        }
      ],
      "source": [
        "from lightfm.cross_validation import random_train_test_split\n",
        "from scipy import sparse\n",
        "\n",
        "# split data into train and test sets\n",
        "train_interactions, test_interactions = random_train_test_split(sparse.csr_matrix(binary_ratings_matrix), test_percentage=0.2, random_state=random_state)\n",
        "train_interactions = train_interactions.toarray()\n",
        "test_interactions = test_interactions.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jannik\\anaconda3\\envs\\rsenv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(943, 100) (100, 1682)\n"
          ]
        }
      ],
      "source": [
        "n_attrs=100\n",
        "\n",
        "nmf = NMF(n_components=n_attrs, solver=\"mu\", max_iter=500)\n",
        "user_representation = nmf.fit_transform(binary_ratings_matrix)\n",
        "item_representation = nmf.components_\n",
        "print(user_representation.shape, item_representation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create RS Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weZ5C2P3s8Xb"
      },
      "outputs": [],
      "source": [
        "recsys = trecs.models.ContentFiltering(\n",
        "    user_representation=user_representation,\n",
        "    item_representation=item_representation,\n",
        "    record_base_state=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQOefImkwABn",
        "outputId": "54d4658a-d00e-41db-8ea2-d55aaa44b516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model representation of users and items are given by:\n",
            "- An all-zeros matrix of users of dimension (943, 100)\n",
            "- A randomly generated matrix of items of dimension (100, 1682)\n"
          ]
        }
      ],
      "source": [
        "print(\"Model representation of users and items are given by:\")\n",
        "print(f\"- An all-zeros matrix of users of dimension {recsys.predicted_user_profiles.shape}\")\n",
        "print(f\"- A randomly generated matrix of items of dimension {recsys.predicted_item_attributes.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "JeEhG7pKq6nH",
        "outputId": "9af19fab-ed23-4de6-8679-9f7dbfc7d6a6"
      },
      "outputs": [],
      "source": [
        "user_pairs = [(u_idx, v_idx) for u_idx in range(recsys.num_users) for v_idx in range(recsys.num_users)]\n",
        "\n",
        "mse = MSEMeasurement(diagnostics=True)\n",
        "\n",
        "recsys.add_metrics(InteractionMeasurement(),\n",
        "                   mse,\n",
        "                   InteractionSpread(),\n",
        "                   RecSimilarity(pairs=user_pairs),\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error: 0.050920292587095864.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean absolute error using the recsys score function and a threshold value to decide when to recommend\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "prediction_threshold = 0.6\n",
        "\n",
        "predicted_scores = recsys.score_fn(user_representation, item_representation)\n",
        "predicted_recs = np.where(predicted_scores > prediction_threshold, 1, 0)\n",
        "\n",
        "mse = mean_squared_error(binary_ratings_matrix, predicted_recs)\n",
        "\n",
        "print(f'Mean squared error: {mse}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Topic Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def get_topic_clusters(interaction_matrix, n_clusters:int=100, n_attrs:int=100, max_iter:int=100, nmf_solver:str=\"mu\"):\n",
        "    \"\"\"\n",
        "    Creates clusters of movies based on their genre.\n",
        "    Inputs:\n",
        "        binary_ratings_matrix: a binary matrix of users and movies\n",
        "        n_attrs: number of attributes to use in NMF\n",
        "        nmf_solver: solver to use in NMF\n",
        "    Outputs:\n",
        "        clusters: a list of cluster assignments\n",
        "    \"\"\"\n",
        "    # Create topic clusters\n",
        "    #create co-occurence matrix from binary_interaction_matrix\n",
        "    co_occurence_matrix = interaction_matrix.T @ interaction_matrix\n",
        "    co_occurence_matrix\n",
        "\n",
        "    # Matrix factorize co_occurence_matrix to get embeddings\n",
        "    nmf_cooc = NMF(n_components=n_attrs, solver=nmf_solver, max_iter=max_iter)\n",
        "    W_topics = nmf_cooc.fit_transform(co_occurence_matrix)\n",
        "\n",
        "    # cluster W_topics\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(W_topics)\n",
        "\n",
        "    # assign nearest cluster to observation\n",
        "    cluster_ids = kmeans.predict(W_topics)\n",
        "\n",
        "    return cluster_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "topics = get_topic_clusters(binary_ratings_matrix, n_clusters=50, n_attrs=n_attrs, nmf_solver=\"mu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate example recommnedations\n",
        "recs = recsys.recommend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate diversity, novelty, \n",
        "imp.reload(src.evaluation_metrics)\n",
        "from src.evaluation_metrics import calculate_diversity, calculate_novelty, calculate_spread, calculate_serendipity\n",
        "\n",
        "def calculate_diversity_metrics(topics, recs):\n",
        "    \"\"\"\n",
        "    Calculates diversity metrics for a set of recommendations.\n",
        "    Inputs:\n",
        "        topics: a list of cluster assignments\n",
        "        recs: a list of recommendations\n",
        "    Outputs:\n",
        "        diversity_metrics: a dictionary of diversity metrics\n",
        "    \"\"\"\n",
        "    diversity, serendipity, spread, novelty = 0, 0, 0, 0\n",
        "    for user_id, slate in enumerate(recs):\n",
        "        # novelty += calculate_novelty(slate, len(recs), binary_ratings_matrix)\n",
        "        # serendipity += calculate_serendipity(slate, user_representation[user_id])\n",
        "        # spread += calculate_spread(slate)\n",
        "        diversity += calculate_diversity(topics, slate)\n",
        "\n",
        "    [diversity, serendipity, spread, novelty] = np.divide([diversity, serendipity, spread, novelty], len(recs)) \n",
        "\n",
        "    diversity_metrics = {\n",
        "        'novelty': novelty,\n",
        "        'serendipity': serendipity,\n",
        "        'spread': spread,\n",
        "        'diversity': diversity,\n",
        "    }\n",
        "    return diversity_metrics\n",
        "\n",
        "# print key and value of calcualte_diversity_metrics\n",
        "diversity_metrics = calculate_diversity_metrics(topics, recs)\n",
        "for key, value in diversity_metrics.items():\n",
        "    print(f'{key}: {value}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Re-rank recommendations\n",
        "There are two main approaches in this section to re-ranking the recommendations.\n",
        "1. Only change the order of the top k recommendations\n",
        "2. Consider an unreasonably large set of recommendations, re-order that and then select the top k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get example recommendations before re-ranking\n",
        "recs = recsys.recommend()\n",
        "\n",
        "# Calculate mean average precision\n",
        "def calculate_mean_average_precision(recs, interactions_matrix):\n",
        "    \"\"\"\n",
        "    Calculates mean average precision for a set of recommendations.\n",
        "    Inputs:\n",
        "        recs: a list of recommendations\n",
        "        binary_ratings_matrix: a binary matrix of interactions between users and items\n",
        "    Outputs:\n",
        "        map: mean average precision\"\"\"\n",
        "    precision = 0\n",
        "    for user_id, slate in enumerate(recs):\n",
        "        for item_id in slate:\n",
        "            if interactions_matrix[user_id][item_id] == 1:\n",
        "                precision += 1\n",
        "    map = precision / (len(recs) * len(recs[0]))\n",
        "    return map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean absolute precision: 95.09%.\n",
            "novelty: 0.0%\n",
            "serendipity: 0.0%\n",
            "spread: 0.0%\n",
            "diversity: 82.15%\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics for myopic RS\n",
        "k=3\n",
        "top_k_recs = recs[:, 0:k]\n",
        "map = calculate_mean_average_precision(top_k_recs, binary_ratings_matrix)\n",
        "print(f'Mean absolute precision: {round(map*100, 2)}%.')\n",
        "\n",
        "# print key and value of calcualte_diversity_metrics\n",
        "diversity_metrics = calculate_diversity_metrics(topics, top_k_recs)\n",
        "for key, value in diversity_metrics.items():\n",
        "    print(f'{key}: {np.round(value*100, 2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate cosine similarity for items in slate\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def calculate_cosine_similarities(slate, item_representation):\n",
        "    \"\"\"\n",
        "    Calculates cosine similarity for a set of recommendations.\n",
        "    Inputs:\n",
        "        slate: a list of recommendations\n",
        "        item_representation: a matrix of item representations\n",
        "    Outputs:\n",
        "        cosine_similarity: mean average precision\n",
        "    \"\"\"\n",
        "    cosine_similarities = []\n",
        "    for item_id in slate:\n",
        "        cosine_similarity = 0\n",
        "        for item_id_2 in slate:\n",
        "            if item_id != item_id_2:\n",
        "                vec_1 = item_representation[:, item_id]\n",
        "                vec_2 = item_representation[:, item_id_2]\n",
        "                vec_prod = np.dot(vec_1, vec_2) / (norm(vec_1) * norm(vec_2))\n",
        "                cosine_similarity += vec_prod\n",
        "        cosine_similarities.append(cosine_similarity)\n",
        "    return cosine_similarities\n",
        "\n",
        "cosine_similarities = calculate_cosine_similarities(recs[0], item_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-ranking scores\n",
        "def re_rank_scores(item_representation, recommendations):\n",
        "    \"\"\"\n",
        "    Re-ranks scores for a set of recommendations.\n",
        "    Inputs:\n",
        "        item_representation: a matrix of item representations\n",
        "        recommendations: a list of recommendations\n",
        "    Outputs:\n",
        "        re_ranked_recommendations: a list of re-ranked recommendations\n",
        "    \"\"\"\n",
        "    exps = [np.round(x * 0.1, 1) for x in range(0, len(recommendations[0]))][::-1]\n",
        "    initial_scores = np.exp(exps)\n",
        "    re_ranked_recommendations = np.zeros_like(recommendations)\n",
        "    \n",
        "    for i, slate in enumerate(recommendations):\n",
        "        # print(f\"Slate:\\t\\t\\t{slate}\")\n",
        "        cosine_similarities = calculate_cosine_similarities(slate, item_representation=item_representation)\n",
        "        # multiply cosine_similarities with each list in recommendations\n",
        "        re_ranked_scores = initial_scores * 1/cosine_similarities\n",
        "        # print(f'Initial Scores:\\t\\t{np.round(initial_scores, 2)}')\n",
        "        # print(f'Re-ranked scores:\\t{np.round(re_ranked_scores, 2)}')\n",
        "        tup = list(zip(slate, re_ranked_scores))\n",
        "        tup.sort(key = lambda x: x[1], reverse=True)\n",
        "        # create list from second element in each tuple in tup\n",
        "        re_ranked_slate = np.array([x[0] for x in tup])\n",
        "        # print(f\"Re-ranked Slate:\\t{re_ranked_slate}\")\n",
        "        re_ranked_recommendations[i] = re_ranked_slate\n",
        "\n",
        "    return re_ranked_recommendations\n",
        "\n",
        "re_ranked_recs = re_rank_scores(item_representation, recs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean absolute precision: 93.18%.\n",
            "novelty: 0.0%\n",
            "serendipity: 0.0%\n",
            "spread: 0.0%\n",
            "diversity: 89.86%\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics for myopic RS\n",
        "top_k_reranked_recs = re_ranked_recs[:, 0:k]\n",
        "map = calculate_mean_average_precision(top_k_reranked_recs, binary_ratings_matrix)\n",
        "print(f'Mean absolute precision: {round(map*100, 2)}%.')\n",
        "\n",
        "# print key and value of calcualte_diversity_metrics\n",
        "diversity_metrics = calculate_diversity_metrics(topics, top_k_reranked_recs)\n",
        "for key, value in diversity_metrics.items():\n",
        "    print(f'{key}: {np.round(value*100, 2)}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.15 ('rsenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ff424ff1c077e7075cac16d9e16e601aa03a34fd87e9d6557d5c3f29437c7df"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
