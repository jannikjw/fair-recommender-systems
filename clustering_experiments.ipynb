{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lyzbdeoNVB7V"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (plotting.py, line 115)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/envs/rsenv2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_24539/1027551545.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from src.plotting import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/jjw2196/fair-recommender-systems/src/plotting.py\"\u001b[0;36m, line \u001b[0;32m115\u001b[0m\n\u001b[0;31m    def plot_tsne(df, perplexity n_clusters):\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from importlib import reload\n",
    "from trecs.metrics import MSEMeasurement, InteractionSpread, InteractionSpread, InteractionSimilarity, RecSimilarity, RMSEMeasurement, InteractionMeasurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo\n",
    "import src.globals as globals\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from wrapper.models.bubble import BubbleBurster\n",
    "from src.utils import *\n",
    "from src.plotting import *\n",
    "from src.scoring_functions import cosine_sim, entropy, content_fairness\n",
    "from wrapper.metrics.evaluation_metrics import SerendipityMetric, DiversityMetric, NoveltyMetric, TopicInteractionMeasurement, MeanNumberOfTopics\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "globals.initialize()\n",
    "# plt.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating RecommenderSystem on MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attrs=20\n",
    "max_iter=1000\n",
    "n_clusters=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ratings_matrix = load_and_process_movielens(file_path='data/ml-100k/u.data')\n",
    "# Get user and item representations using NMF\n",
    "user_representation, item_representation = create_embeddings(binary_ratings_matrix, n_attrs=n_attrs, max_iter=max_iter)\n",
    "# Define topic clusters using NMF\n",
    "item_cluster_ids, item_cluster_centers = get_clusters(item_representation.T, name='item', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)\n",
    "user_cluster_ids, user_cluster_centers = get_clusters(user_representation, name='user', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)\n",
    "\n",
    "print(item_cluster_centers.shape)\n",
    "print(user_cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Item Clusters to Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean_distance_matrix = np.empty((n_clusters, n_clusters), dtype=float)\n",
    "# for i, user_cluster in enumerate(user_cluster_centers):\n",
    "#     for j, item_cluster in enumerate(item_cluster_centers):\n",
    "#         euclidean_distance_matrix[i, j] = np.linalg.norm(user_cluster - item_cluster)\n",
    "\n",
    "# # # remove most popular item cluster \n",
    "# # columns_to_drop = np.argmax(np.bincount(item_cluster_ids))\n",
    "# # print(columns_to_drop)\n",
    "# # euclidean_distance_df = pd.DataFrame(euclidean_distance_matrix).drop(columns=columns_to_drop)\n",
    "\n",
    "# # # display(euclidean_distance_df)\n",
    "# # euclidean_distance_matrix = np.array(euclidean_distance_df)\n",
    "\n",
    "# user_cluster_item_cluster_assignments = np.argmin(euclidean_distance_matrix, axis=1)\n",
    "# print(user_cluster_item_cluster_assignments) # Problem: many user clusters are close to the same item cluster\n",
    "# print(f'Number of unique item clusters for user clusters: {len(np.unique(user_cluster_item_cluster_assignments))}')\n",
    "\n",
    "# # assign each user in user_representation the a value based on user_cluster_item_cluster_assignment\n",
    "# user_to_item_cluster_assignment = np.empty((len(user_representation)), dtype=int)\n",
    "# for i, user in enumerate(user_to_item_cluster_assignment):\n",
    "#     user_to_item_cluster_assignment[i] = user_cluster_item_cluster_assignments[user_cluster_ids[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test whether the closest cluster includes many of the items viewed by the user\n",
    "user_to_item_cluster_assignment = user_topic_mapping(user_representation, item_cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "from scipy import interpolate\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of occurences in cluster_ids\n",
    "def plot_cluster_distributions(binary_ratings_matrix, user_cluster_ids, item_cluster_ids):\n",
    "    fig, axs = plt.subplots(2,2, figsize=(15, 7))\n",
    "\n",
    "    # plot bar chart where x axis is cluster_id and height is number of items in a cluster\n",
    "    cluster_counts = np.bincount(user_cluster_ids)\n",
    "    axs[0, 0].bar(x=range(len(cluster_counts)), height=cluster_counts)\n",
    "    axs[0, 0].set_xticks(range(len(cluster_counts)), range(0, len(cluster_counts)))\n",
    "    axs[0, 0].set_title('Users per cluster')\n",
    "\n",
    "    # count number of occurences in cluster_ids\n",
    "    cluster_counts = np.bincount(item_cluster_ids)\n",
    "    axs[0, 1].bar(x=range(len(cluster_counts)), height=cluster_counts)\n",
    "    axs[0, 1].set_xticks(range(len(cluster_counts)), range(0, len(cluster_counts)))\n",
    "    axs[0, 1].set_title('Items per cluster')\n",
    "\n",
    "    # Interactions per user cluster\n",
    "    interactions_per_user_cluster = np.empty(len(np.unique(user_cluster_ids)), dtype=int)\n",
    "    for i, id in enumerate(user_cluster_ids):\n",
    "        interactions_per_user_cluster[id] += np.sum(binary_ratings_matrix[i, :])\n",
    "\n",
    "    # Interactions per item cluster\n",
    "    interactions_per_item_cluster = np.empty(len(np.unique(item_cluster_ids)), dtype=int)\n",
    "    for i, id in enumerate(item_cluster_ids):\n",
    "        interactions_per_item_cluster[id] += np.sum(binary_ratings_matrix[:, i])\n",
    "\n",
    "    axs[1, 0].bar(x=range(len(interactions_per_user_cluster)), height=interactions_per_user_cluster)\n",
    "    axs[1, 0].set_xticks(range(len(np.unique(user_cluster_ids))), range(0, len(np.unique(user_cluster_ids))))\n",
    "    axs[1, 0].set_title('Interactions by User Cluster')\n",
    "\n",
    "    axs[1, 1].bar(x=range(len(interactions_per_item_cluster)), height=interactions_per_item_cluster)\n",
    "    axs[1, 1].set_xticks(range(len(np.unique(item_cluster_ids))), range(0, len(np.unique(item_cluster_ids))))\n",
    "    axs[1, 1].set_title('Interactions by Item Cluster')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters prior to Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_distributions(binary_ratings_matrix, user_cluster_ids, item_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using user representation and clusters from NMF to visualize user separation\n",
    "x = user_representation\n",
    "y = user_to_item_cluster_assignment\n",
    "perplexity = 50\n",
    "\n",
    "df_prev = apply_tsne_2d(x, y, perplexity=perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(df_prev, perplexity=perplexity, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems:\n",
    "#   1. Matched user centroids to item centroids based on minimium euclidean distance \n",
    "#      -> only 5 item clusters are selected\n",
    "#   2. Matched users to item centroids based on min. euclidean distance \n",
    "#      -> almost 800 users go to same item cluster\n",
    "#   3. Generally, the data is very skewed (this is realistic but quickly assign most observations\n",
    "#      to the same cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters post simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preferences after model ran\n",
    "pref_dir = 'artefacts/final_preferences/'\n",
    "\n",
    "# Only compare ranking mechanisms with each other that have the same model parameters\n",
    "n_attrs = n_attrs\n",
    "n_clusters = n_clusters\n",
    "train_timesteps = 10\n",
    "run_timesteps = 100\n",
    "drift = 0.05\n",
    "attention_exp = -0.8\n",
    "pair_all = False\n",
    "\n",
    "parameters = f'{train_timesteps}trainTimesteps_{run_timesteps}runTimesteps_{n_attrs}nAttrs_{n_clusters}nClusters_{drift}Drift_{attention_exp}AttentionExp_{pair_all}PairAll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_final_preferences(config, parameters_str):\n",
    "    file_prefix = f\"{config['model_name']}_final_preferences_\"\n",
    "    \n",
    "    if config['requires_alpha']:\n",
    "        parameters_str += f\"_{config['alpha']}Lambda\"\n",
    "\n",
    "    # Load file\n",
    "    path = pref_dir + file_prefix + parameters_str + '.npy'\n",
    "    final_user_pref = np.load(path, allow_pickle=True)\n",
    "    # Map users to the fixed item clusters based on their embedding distances to the item_cluster_centers\n",
    "    final_user_pref_mapping = user_topic_mapping(final_user_pref, item_cluster_centers)\n",
    "    \n",
    "    return final_user_pref, final_user_pref_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myopic\n",
    "myopic_config = {\n",
    "    'model_name': 'myopic',\n",
    "    'requires_alpha': False,\n",
    "}\n",
    "\n",
    "myopic_final_user_pref, myopic_final_user_pref_mapping = load_final_preferences(myopic_config, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = apply_tsne_2d(myopic_final_user_pref, myopic_final_user_pref_mapping, perplexity=perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_comparison(df_prev, df_post, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append(user_to_item_cluster_assignment)\n",
    "data.append(final_user_pref_mapping)\n",
    "data = np.array(data).T\n",
    "cluster_changes_df = pd.DataFrame(data, columns=['initial_cluster', 'final_cluster'])\n",
    "cluster_changes_df = cluster_changes_df[cluster_changes_df['initial_cluster'] != cluster_changes_df['final_cluster']]\n",
    "print(model_name, ': Number of people who changed clusters: ', cluster_changes_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Sim\n",
    "model_name = 'entropy'\n",
    "myopic_config = {\n",
    "    'model_name': 'entropy',\n",
    "    'requires_alpha': True,\n",
    "    'alpha': 0.1,\n",
    "}\n",
    "\n",
    "entropy_final_user_pref, entropy_final_user_pref_mapping = load_final_preferences(myopic_config, parameters)\n",
    "\n",
    "df_post = apply_tsne_2d(entropy_final_user_pref, entropy_final_user_pref_mapping, perplexity=perplexity)\n",
    "\n",
    "plot_tsne_comparison(df_prev, df_post)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "rsenv2",
   "language": "python",
   "name": "rsenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c64b5f0e204e2b557bfa409cf6c0678c4f1eefdf2bd314df48e0edc57cda315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
