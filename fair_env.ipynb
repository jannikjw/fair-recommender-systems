{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. How do we distribute documents?\n",
    "2. How does reading a document influence a user?\n",
    "3. How do we simulate a user's past/initial leaning?\n",
    "4. What set of users do we start from? Can we base it on real life or a dataset?\n",
    "5. What features does each document have (clickbaityness, topic, political leaning, quality, ...)?\n",
    "6. How do we define engagement?\n",
    "7. How can we drive a user into a certain direction?\n",
    "8. What assumptions are legitimate? How do you make good assumptions in modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "**Initial Assumptions:**\n",
    "- If a piece is aligned with a person's interest, they prefer it\n",
    "- We present 5 pieces of content to each user \n",
    "- When presented with content, the user clicks on 0 or 1 piece of content^\n",
    "- Content-user response is dependent on | leaning - affinity | is small, the user-response\n",
    "- Every slate (i.e. content recommendation) is treated as a single action (don't consider past )\n",
    "- Content has attributes:\n",
    "    - leaning\n",
    "    - clickbaityness\n",
    "- User has attributes:\n",
    "    - affinity/opinion\n",
    "    - satisfaction\n",
    "- User response has engagement as main characteristic\n",
    "\n",
    "-> Borrow ideas from both interest_explortion and long_term_satisfaction\n",
    "\n",
    "**Advanced Assumptions:**\n",
    "- On each topic, a user has an opinion and a piece of content also has a leaning. The closer opinion and leaning are, the more satisfaction a user derives from the piece of content\n",
    "- If a user likes a piece content their opinion shifts in the direction of the content's leaning  \n",
    "- Users generally do not notice/dislike that they are in a filter bubble\n",
    "- While content might have a general leaning, liking/disliking is more complex than that -> I might agree with the infrastructure bill even though I am a republican -> This effect is stronger the closer to the edge of my filter bubble I am\n",
    "- We could research some social science studies on filter bubbles and why people click on what to model it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Importing generics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Importing RecSim components \n",
    "from recsim.agents import full_slate_q_agent\n",
    "from recsim.environments import long_term_satisfaction\n",
    "from recsim.simulator import runner_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(sess, environment, eval_mode, summary_writer=None):\n",
    "  kwargs = {\n",
    "      'observation_space': environment.observation_space,\n",
    "      'action_space': environment.action_space,\n",
    "      'summary_writer': summary_writer,\n",
    "      'eval_mode': eval_mode,\n",
    "  }\n",
    "  return full_slate_q_agent.FullSlateQAgent(sess, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - slate_size sets the size of the set of elements presented to the user;\n",
    "# - num_candidates specifies the number of documents present in the document database at any given time;\n",
    "# - resample_documents specifies whether the set of candidates should be resampled between time steps according to the document distribution (more on this in [later notebooks](RecSim_Developing_an_Environment.ipynb)).\n",
    "#   finally, we set the random seed.\n",
    "\n",
    "env_config = {\n",
    "  'num_candidates': 20,\n",
    "  'slate_size': 5,\n",
    "  'resample_documents': True,\n",
    "  'seed': seed,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:max_training_steps = 1, number_iterations = 1,checkpoint frequency = 1 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:max_training_steps = 1, number_iterations = 1,checkpoint frequency = 1 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:max_steps_per_episode = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:max_steps_per_episode = 5\n"
     ]
    }
   ],
   "source": [
    "#@title Training the agent\n",
    "tmp_base_dir = '/tmp/recsim/'\n",
    "runner = runner_lib.TrainRunner(\n",
    "    base_dir=tmp_base_dir,\n",
    "    create_agent_fn=create_agent,\n",
    "    env=long_term_satisfaction.create_environment(env_config),\n",
    "    episode_log_file=\"\",\n",
    "    max_steps_per_episode=5,\n",
    "    max_training_steps=1,\n",
    "    num_iterations=1)\n",
    "runner.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Evaluating the agent\n",
    "runner = runner_lib.EvalRunner(\n",
    "    base_dir=tmp_base_dir,\n",
    "    create_agent_fn=create_agent,\n",
    "    env=long_term_satisfaction.create_environment(env_config),\n",
    "    max_eval_episodes=5,\n",
    "    test_mode=True)\n",
    "runner.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tensorboard\n",
    "%tensorboard --logdir=/tmp/recsim/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('rsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "137c6895ff1e4ad4bdd0994a4515bb1506326ea24e2217cfe75aba587b044e56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
