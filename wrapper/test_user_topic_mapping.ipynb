{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_file.py\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../../t-recs/')\n",
    "from trecs.models import ContentFiltering\n",
    "from trecs.metrics import *\n",
    "from trecs.random import Generator\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "ratings_df = pd.read_csv('../data/ml-100k/u.data', \n",
    "    sep=\"\\t\", \n",
    "    names=['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    ")\n",
    "\n",
    "movie_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies_df = pd.read_csv('../data/ml-100k/u.item', sep=\"|\", names=movie_cols, encoding='latin')\n",
    "\n",
    "# display(movies_df.head(2))\n",
    "# print(movies_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_topic_clusters(binary_ratings_matrix, n_attrs:int=100, nmf_solver:str=\"mu\"):\n",
    "    \"\"\"\n",
    "    Creates clusters of movies based on their genre.\n",
    "    Inputs:\n",
    "        binary_ratings_matrix: a binary matrix of users and movies\n",
    "        n_attrs: number of attributes to use in NMF\n",
    "        nmf_solver: solver to use in NMF\n",
    "    Outputs:\n",
    "        clusters: a list of cluster assignments\n",
    "    \"\"\"\n",
    "    # Create topic clusters\n",
    "    #create co-occurence matrix from binary_interaction_matrix\n",
    "    co_occurence_matrix = binary_ratings_matrix.T @ binary_ratings_matrix\n",
    "    co_occurence_matrix\n",
    "\n",
    "    # Matrix factorize co_occurence_matrix to get embeddings\n",
    "    nmf_cooc = NMF(n_components=n_attrs, solver=nmf_solver)\n",
    "    W_topics = nmf_cooc.fit_transform(co_occurence_matrix)\n",
    "\n",
    "    # cluster W_topics\n",
    "    kmeans = KMeans(n_clusters=100, random_state=random_state).fit(W_topics)\n",
    "\n",
    "    # assign nearest cluster to observation\n",
    "    cluster_ids = kmeans.predict(W_topics)\n",
    "\n",
    "    return cluster_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madisonthantu/miniforge3/envs/fairRS/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 100) (100, 1682)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "binary_ratings_df = ratings_df.drop(columns=['Timestamp'])\n",
    "binary_ratings_df.loc[binary_ratings_df['Rating'] > 0, 'Rating'] = 1\n",
    "\n",
    "# turn dataframe into matrix where each movie is a column and each user is a row\n",
    "binary_ratings_matrix = binary_ratings_df.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0).to_numpy()\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from scipy import sparse\n",
    "\n",
    "# split data into train and test sets\n",
    "train_interactions, test_interactions = random_train_test_split(sparse.csr_matrix(binary_ratings_matrix), test_percentage=0.2, random_state=random_state)\n",
    "train_interactions = train_interactions.toarray()\n",
    "test_interactions = test_interactions.toarray()\n",
    "\n",
    "n_attrs=100\n",
    "nmf = NMF(n_components=n_attrs, solver=\"mu\")\n",
    "user_representation = nmf.fit_transform(binary_ratings_matrix)\n",
    "item_representation = nmf.components_\n",
    "print(user_representation.shape, item_representation.shape)\n",
    "\n",
    "# nmf_solver='mu'\n",
    "n_clusters=50\n",
    "\n",
    "num_topics = None\n",
    "item_topics = get_topic_clusters(binary_ratings_matrix, n_attrs=n_attrs)#, nmf_solver=\"mu\")\n",
    "user_topic_history = None\n",
    "item_count = None\n",
    "\n",
    "users = Users(size=(943,100), repeat_interactions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating `BubbleBurster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../')\n",
    "\n",
    "from wrapper.models.bubble import BubbleBurster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble = BubbleBurster(\n",
    "    # num_users=number_of_users,\n",
    "    # num_items=num_items,\n",
    "    # num_attributes=number_of_attributes,\n",
    "    item_topics=item_topics,\n",
    "    user_representation=user_representation,\n",
    "    item_representation=item_representation,\n",
    "    actual_user_representation=users,\n",
    "    record_base_state=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `user_topic_mapping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_profiles, item_attributes = bubble.actual_user_profiles, bubble.actual_item_attributes\n",
    "user_profiles, item_attributes = bubble.predicted_user_profiles, bubble.predicted_item_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 100)\n"
     ]
    }
   ],
   "source": [
    "topics = np.unique(item_topics)#, return_counts=True)\n",
    "# print(type(topics))\n",
    "# print(topics)\n",
    "# break\n",
    "user_item_scores = mo.inner_product(user_profiles, item_attributes)\n",
    "\n",
    "test_user_topic_mapping = np.zeros((user_profiles.shape[0], topics.size))\n",
    "\n",
    "for topic_i in topics:\n",
    "    \n",
    "    topic_idx = np.where(item_topics == topic_i)[0]\n",
    "    # topic_i_user_scores = np.mean(user_item_scores[:, topic_idx], axis=1)\n",
    "    # user_topic_mapping[:,topic_i] = topic_i_user_scores\n",
    "    # ^ Condensed:\n",
    "    test_user_topic_mapping[:,topic_i] = np.mean(user_item_scores[:, topic_idx], axis=1)\n",
    "\n",
    "print(test_user_topic_mapping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import user_topic_mapping\n",
    "\n",
    "result_user_topic_mapping = user_topic_mapping(user_profiles, item_attributes, item_topics)\n",
    "\n",
    "assert(np.array_equal(result_user_topic_mapping, test_user_topic_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(result_user_topic_mapping, test_user_topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 100)\n",
      "(943, 100)\n"
     ]
    }
   ],
   "source": [
    "print(test_user_topic_mapping.shape)\n",
    "print(result_user_topic_mapping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics, topic_counts = np.unique(item_topics, return_counts=True)\n",
    "# user_item_scores = mo.inner_product(user_profiles, item_attributes)\n",
    "\n",
    "# user_topic_mapping = np.zeros((user_profiles.shape[0], topics.size))\n",
    "# # temp = np.zeros((user_profiles.shape[0], topics.size))\n",
    "# # print(user_topic_mapping.shape)\n",
    "\n",
    "# count = 0\n",
    "# for topic_i in topics:\n",
    "    \n",
    "#     topic_idx = np.where(item_topics == topic_i)[0]\n",
    "#     # print(topic_idx.shape)\n",
    "#     assert (len(topic_idx) == topic_counts[topic_i]), \"number of topic indices is not equal to number of topic_i instances in item_topics ):\"\n",
    "    \n",
    "#     topic_i_user_scores = np.sum(user_item_scores[:, topic_idx], axis=1)\n",
    "#     assert (np.sum(user_item_scores[0,topic_idx]).round(decimals=10) == topic_i_user_scores[0].round(decimals=10)), f\"{count}\"\n",
    "#     count += 1\n",
    "    \n",
    "#     # temp[:,topic_i] = topic_i_user_scores\n",
    "#     user_topic_mapping[:,topic_i] = topic_i_user_scores / topic_idx.size \n",
    "#     # print(topic_user_mapping.shape)\n",
    "#     # break\n",
    "\n",
    "# print(count)\n",
    "# print(user_topic_mapping.shape)\n",
    "\n",
    "# topics, topic_counts = np.unique(item_topics, return_counts=True)\n",
    "# user_item_scores = mo.inner_product(user_profiles, item_attributes)\n",
    "\n",
    "# temp = np.zeros((user_profiles.shape[0], topics.size))\n",
    "# # temp = np.zeros((user_profiles.shape[0], topics.size))\n",
    "# # print(user_topic_mapping.shape)\n",
    "\n",
    "# count = 0\n",
    "# for topic_i in topics:\n",
    "    \n",
    "#     topic_idx = np.where(item_topics == topic_i)[0]\n",
    "#     # print(topic_idx.shape)\n",
    "#     assert (len(topic_idx) == topic_counts[topic_i]), \"number of topic indices is not equal to number of topic_i instances in item_topics ):\"\n",
    "    \n",
    "#     # topic_i_user_scores = np.sum(user_item_scores[:, topic_idx], axis=1)\n",
    "#     # assert (np.sum(user_item_scores[0,topic_idx]).round(decimals=10) == topic_i_user_scores[0].round(decimals=10)), f\"{count}\"\n",
    "#     temp2 = np.mean(user_item_scores[:, topic_idx], axis=1)\n",
    "#     # print(temp.shape)\n",
    "#     count += 1\n",
    "#     # break\n",
    "#     temp[:,topic_i] = temp2\n",
    "#     # temp[:,topic_i] = topic_i_user_scores\n",
    "#     # user_topic_mapping[:,topic_i] = topic_i_user_scores / topic_idx.size \n",
    "#     # print(topic_user_mapping.shape)\n",
    "#     # break\n",
    "\n",
    "# print(count)\n",
    "# print(temp.shape)\n",
    "\n",
    "# count = 0\n",
    "# for i in range(len(topics)):\n",
    "#     topic_idx = np.where(item_topics == i)[0]\n",
    "#     assert(np.array_equal(bubble.actual_user_item_scores[0, np.where(item_topics == i)].round(decimals=10), np.expand_dims(user_item_scores[0, topic_idx].round(decimals=10), axis=0)))\n",
    "#     # assert(np.array_equal(topic_user_mapping[:,i], ))\n",
    "# # asse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82ad1e6da8c8551612185ff57ab4e881be31b0c67a550f3cbdb2f98515f5914e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('fairRS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
