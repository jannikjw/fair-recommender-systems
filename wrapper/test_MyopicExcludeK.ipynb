{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madisonthantu/miniforge3/envs/fairRS/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n",
      "/Users/madisonthantu/miniforge3/envs/fairRS/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 100) (100, 1682)\n"
     ]
    }
   ],
   "source": [
    "# some_file.py\n",
    "import sys\n",
    "sys.path.insert(1, '../../t-recs/')\n",
    "from trecs.metrics import *\n",
    "from trecs.random import Generator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "ratings_df = pd.read_csv('../../ml-100k/u.data', \n",
    "    sep=\"\\t\", \n",
    "    names=['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    ")\n",
    "\n",
    "movie_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies_df = pd.read_csv('../../ml-100k/u.item', sep=\"|\", names=movie_cols, encoding='latin')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_topic_clusters(binary_ratings_matrix, n_attrs:int=100, nmf_solver:str=\"mu\"):\n",
    "    \"\"\"\n",
    "    Creates clusters of movies based on their genre.\n",
    "    Inputs:\n",
    "        binary_ratings_matrix: a binary matrix of users and movies\n",
    "        n_attrs: number of attributes to use in NMF\n",
    "        nmf_solver: solver to use in NMF\n",
    "    Outputs:\n",
    "        clusters: a list of cluster assignments\n",
    "    \"\"\"\n",
    "    # Create topic clusters\n",
    "    #create co-occurence matrix from binary_interaction_matrix\n",
    "    co_occurence_matrix = binary_ratings_matrix.T @ binary_ratings_matrix\n",
    "    co_occurence_matrix\n",
    "\n",
    "    # Matrix factorize co_occurence_matrix to get embeddings\n",
    "    nmf_cooc = NMF(n_components=n_attrs, solver=nmf_solver)\n",
    "    W_topics = nmf_cooc.fit_transform(co_occurence_matrix)\n",
    "\n",
    "    # cluster W_topics\n",
    "    kmeans = KMeans(n_clusters=100, random_state=random_state).fit(W_topics)\n",
    "\n",
    "    # assign nearest cluster to observation\n",
    "    cluster_ids = kmeans.predict(W_topics)\n",
    "\n",
    "    return cluster_ids\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "binary_ratings_df = ratings_df.drop(columns=['Timestamp'])\n",
    "binary_ratings_df.loc[binary_ratings_df['Rating'] > 0, 'Rating'] = 1\n",
    "\n",
    "# turn dataframe into matrix where each movie is a column and each user is a row\n",
    "binary_ratings_matrix = binary_ratings_df.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0).to_numpy()\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from scipy import sparse\n",
    "\n",
    "# split data into train and test sets\n",
    "train_interactions, test_interactions = random_train_test_split(sparse.csr_matrix(binary_ratings_matrix), test_percentage=0.2, random_state=random_state)\n",
    "train_interactions = train_interactions.toarray()\n",
    "test_interactions = test_interactions.toarray()\n",
    "\n",
    "n_attrs=100\n",
    "nmf = NMF(n_components=n_attrs, solver=\"mu\")\n",
    "user_representation = nmf.fit_transform(binary_ratings_matrix)\n",
    "item_representation = nmf.components_\n",
    "print(user_representation.shape, item_representation.shape)\n",
    "\n",
    "num_topics = None\n",
    "item_topics = get_topic_clusters(binary_ratings_matrix, n_attrs=n_attrs, nmf_solver=\"mu\")\n",
    "user_topic_history = None\n",
    "item_count = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MyopicExcludeK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.excl_k_myopic import MyopicExcludeK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys = MyopicExcludeK(\n",
    "    item_topics=item_topics,\n",
    "    user_representation=user_representation,\n",
    "    item_representation=item_representation,\n",
    "    record_base_state=True,\n",
    "    excludeK=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(1682,)\n",
      "(943, 100)\n",
      "[0.]\n",
      "(1682,)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(recsys.num_topics)\n",
    "print(recsys.item_topics.shape)\n",
    "print(recsys.user_topic_history.shape)\n",
    "print(np.unique(recsys.user_topic_history))\n",
    "print(recsys.item_count.shape) \n",
    "print(recsys.excludeK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the current metrics:\n",
      "[<trecs.metrics.measurement.MSEMeasurement object at 0x15d786850>, <trecs.metrics.measurement.InteractionSpread object at 0x15d807910>, <trecs.metrics.measurement.AverageFeatureScoreRange object at 0x15d786d30>]\n"
     ]
    }
   ],
   "source": [
    "recsys.add_metrics(MSEMeasurement(), InteractionSpread(), AverageFeatureScoreRange())\n",
    "print(\"These are the current metrics:\")\n",
    "print(recsys.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# now we run the model\n",
    "recsys.run(timesteps=1)\n",
    "measurements = recsys.get_measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82ad1e6da8c8551612185ff57ab4e881be31b0c67a550f3cbdb2f98515f5914e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('fairRS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
