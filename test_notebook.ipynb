{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/hcy50x855gvf2b1qwkjstnvh0000gn/T/ipykernel_6428/2732531481.py:27: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from importlib import reload\n",
    "\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../t-recs/')\n",
    "from trecs.metrics import MSEMeasurement, InteractionSpread, InteractionSpread, InteractionSimilarity, RecSimilarity, RMSEMeasurement, InteractionMeasurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo\n",
    "import src.globals as globals\n",
    "import seaborn as sns\n",
    "\n",
    "from wrapper.models.bubble import BubbleBurster\n",
    "from src.utils import *\n",
    "from src.plotting import plot_measurements \n",
    "from src.scoring_functions import cosine_sim, entropy, content_fairness\n",
    "from wrapper.metrics.evaluation_metrics import *\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "globals.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attrs=20\n",
    "max_iter=1000\n",
    "n_clusters=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fn = None #'content_fairness'\n",
    "probabilistic = False\n",
    "globals.ALPHA = 0.2\n",
    "alpha = globals.ALPHA\n",
    "\n",
    "# User parameters\n",
    "drift = 0.05\n",
    "attention_exp=-0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ratings_matrix = load_and_process_movielens(file_path='data/ml-100k/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Get user and item representations using NMF\n",
    "user_representation, item_representation = create_embeddings(binary_ratings_matrix, n_attrs=n_attrs, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1682)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clusters.\n",
      "Loaded clusters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madisonthantu/miniforge3/envs/fairRS/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KMeans from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/madisonthantu/miniforge3/envs/fairRS/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KMeans from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define topic clusters using NMF\n",
    "item_cluster_ids, item_cluster_centers = get_clusters(item_representation.T, name='item', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)\n",
    "user_cluster_ids, user_cluster_centers = get_clusters(user_representation, name='user', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 20\n",
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_representation)\n",
    "num_items = len(item_representation)\n",
    "print(f'Number of items: {num_items}')\n",
    "print(f'Number of users: {num_users}')\n",
    "\n",
    "users = Users(actual_user_profiles=user_representation, \n",
    "              repeat_interactions=False, \n",
    "              drift=drift,\n",
    "              attention_exp=attention_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user_pairs by pairing users only with others that are not in the same cluster\n",
    "user_item_cluster_mapping = user_topic_mapping(user_representation, item_cluster_centers) # TODO: Remove?\n",
    "experiment_name = 'users_by_topic'\n",
    "# Create user_pairs by pairing users only with others that are not in the same cluster\n",
    "inter_cluster_user_pairs, intra_cluster_user_pairs = create_cluster_user_pairs(user_item_cluster_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSEMeasurement()\n",
    "measurements = [\n",
    "    InteractionMeasurement(),\n",
    "    MSEMeasurement(),  \n",
    "    InteractionSpread(),                \n",
    "    InteractionSimilarity(pairs=inter_cluster_user_pairs, name='inter_cluster_interaction_similarity'), \n",
    "    InteractionSimilarity(pairs=intra_cluster_user_pairs, name='intra_cluster_interaction_similarity'), \n",
    "    RecSimilarity(pairs=inter_cluster_user_pairs, name='inter_cluster_rec_similarity'), \n",
    "    RecSimilarity(pairs=intra_cluster_user_pairs, name='intra_cluster_rec_similarity'), \n",
    "    UserMSEMeasurement(),\n",
    "    SerendipityMetric(), \n",
    "    DiversityMetric(), \n",
    "    NoveltyMetric(),\n",
    "    RecallMeasurement(),\n",
    "    MeanNumberOfTopics(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "config = {\n",
    "    'actual_user_representation': users,\n",
    "    'actual_item_representation': item_representation,\n",
    "    'item_topics': item_cluster_ids,\n",
    "    'num_attributes': n_attrs,\n",
    "    'num_items_per_iter': 10,\n",
    "    'seed': 42,\n",
    "    'record_base_state': True,\n",
    "}\n",
    "\n",
    "model_name='myopic'\n",
    "requires_alpha = False\n",
    "\n",
    "if score_fn:\n",
    "    if score_fn == 'cosine_sim':\n",
    "        config['score_fn'] = cosine_sim\n",
    "        requires_alpha = True\n",
    "    elif score_fn == 'entropy':\n",
    "        config['score_fn'] = entropy\n",
    "        requires_alpha = True\n",
    "    elif score_fn == 'content_fairness':\n",
    "        config['score_fn'] = content_fairness        \n",
    "    else:\n",
    "        raise Exception('Given score function does not exist.')\n",
    "    model_name = score_fn\n",
    "\n",
    "if probabilistic:\n",
    "    config['probabilistic_recommendations'] = True\n",
    "    model_name += '_prob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BubbleBurster(**config)\n",
    "\n",
    "model.add_metrics(*measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fair Model\n",
    "train_timesteps=5\n",
    "model.startup_and_train(timesteps=train_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:20<00:00,  7.01s/it]\n"
     ]
    }
   ],
   "source": [
    "run_timesteps=20\n",
    "model.run(timesteps=run_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements saved.\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "reload(src.utils)\n",
    "from src.utils import *\n",
    "    \n",
    "# Determine file name based on parameter values\n",
    "parameters = f'_{train_timesteps}trainTimesteps_{run_timesteps}runTimesteps_{n_attrs}nAttrs_{n_clusters}nClusters_{drift}Drift_{attention_exp}AttentionExp'\n",
    "if requires_alpha:\n",
    "    parameters += f'_{alpha}Lambda'\n",
    "\n",
    "# Save actual user preferences\n",
    "final_preferences_dir = 'artefacts/supplementary/final_preferences/'\n",
    "file_prefix = f'{model_name}_final_preferences'\n",
    "final_preferences_path = final_preferences_dir + file_prefix + parameters + '.npy'\n",
    "np.save(final_preferences_path, model.users.actual_user_profiles.value, allow_pickle=True)\n",
    "\n",
    "# Save measurements\n",
    "measurements_dir = f'artefacts/supplementary/measurements/'\n",
    "file_prefix = f'{model_name}_measurements'\n",
    "\n",
    "measurements_path = measurements_dir + file_prefix + parameters + '.csv'\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "measurements_df = load_or_create_measurements_df(model, model_name, train_timesteps, measurements_path)\n",
    "# measurements_df['interaction_histogram'] = measurements_df['interaction_histogram'].tolist()\n",
    "# saving interaction histogram\n",
    "path_interaction_histogram = f'{measurements_dir}{model_name}_interaction_histogram{parameters}.csv'\n",
    "interaction_hist = measurements_df['interaction_histogram'].copy()\n",
    "interaction_hist[0] = np.repeat(np.nan, interaction_hist[1].shape[0], axis=0)\n",
    "interaction_hist = np.stack(interaction_hist.values)\n",
    "test = pd.DataFrame(interaction_hist)\n",
    "test.to_csv(path_interaction_histogram)\n",
    "# saving use_mse histogram\n",
    "path_user_mse_histogram = f'{measurements_dir}{model_name}_user_mse_histogram{parameters}.csv'\n",
    "user_mse = measurements_df['user_mse'].copy()\n",
    "user_mse = np.stack(user_mse.values)\n",
    "test = pd.DataFrame(user_mse)\n",
    "test.to_csv(path_user_mse_histogram)\n",
    "# saving all measurements\n",
    "measurements_df.to_csv(measurements_path)\n",
    "print('Measurements saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measurements(dfs, parameters_df):\n",
    "    fig, ax = plt.subplots(4, 3, figsize=(15, 15))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    # plot rec_similarity with timesteps on x axis\n",
    "    legend_lines, legend_names = [], []\n",
    "    for i, df in enumerate(dfs):\n",
    "        ts = df['timesteps']\n",
    "        name = parameters_df.loc[i, 'model_name']\n",
    "        if not np.isnan(parameters_df.loc[i, 'Lambda']):\n",
    "             name += f\" (Lambda: {parameters_df.loc[i, 'Lambda']})\" \n",
    "        legend_names.append(name)\n",
    "        \n",
    "        line, = ax[0,0].plot(ts, df['mse'], label=name)\n",
    "        ax[0,1].plot(ts, df['user_mse'], label=name)\n",
    "        ax[0,2].plot(ts, df['recall_at_k'], label=name)\n",
    "    \n",
    "        if 'interaction_spread' in df.columns:\n",
    "            ax[1,0].plot(ts, df['interaction_spread'], label=name, alpha=0.5)\n",
    "        if 'inter_cluster_interaction_similarity' in df.columns:\n",
    "            ax[1,1].plot(ts, df['inter_cluster_interaction_similarity'], label=name, alpha=0.5)\n",
    "        if 'intra_cluster_interaction_similarity' in df.columns:\n",
    "            ax[1,2].plot(ts, df['intra_cluster_interaction_similarity'], label=name, alpha=0.5)\n",
    "\n",
    "        if 'diversity_metric' in df.columns:\n",
    "            ax[2,0].plot(ts, df['diversity_metric'], label=name, alpha=0.5)\n",
    "        if 'inter_cluster_rec_similarity' in df.columns:\n",
    "            ax[2,1].plot(ts, df['inter_cluster_rec_similarity'], label=name, alpha=0.5)\n",
    "        if 'intra_cluster_rec_similarity' in df.columns:\n",
    "            ax[2,2].plot(ts, df['intra_cluster_rec_similarity'], label=name, alpha=0.5)\n",
    "\n",
    "        if 'serendipity_metric' in df.columns:\n",
    "            ax[3,0].plot(ts, df['serendipity_metric'], label=name, alpha=0.5)\n",
    "        if 'novelty_metric' in df.columns:\n",
    "            ax[3,1].plot(ts, df['novelty_metric'], label=name, alpha=0.5)\n",
    "        if 'mean_num_topics' in df.columns:\n",
    "            ax[3,2].plot(ts, df['mean_num_topics'], label=name, alpha=0.5)\n",
    "        \n",
    "        legend_lines.append(line)\n",
    "\n",
    "    for a in ax:\n",
    "        for b in a:\n",
    "            b.set_xlabel('Timestep')\n",
    "\n",
    "    ax[0, 0].set_title('Mean Squared Error')\n",
    "    ax[0, 0].set_ylabel('MSE')\n",
    "    \n",
    "    ax[0, 1].set_title('User Mean Squared Error')\n",
    "    ax[0, 1].set_ylabel('MSE')\n",
    "    ax[0, 1].set_xlabel('User ID')\n",
    "    \n",
    "    ax[0, 2].set_title('Recall')\n",
    "    ax[0, 2].set_ylabel('Recall')\n",
    "    \n",
    "    ax[1, 0].set_title('Interaction Spread')\n",
    "    ax[1, 0].set_ylabel('Jaccard Similarity')\n",
    "    \n",
    "    ax[1, 1].set_title('Inter Cluster Interaction Similarity')\n",
    "    ax[1, 1].set_ylabel('Jaccard Similarity')\n",
    "    \n",
    "    ax[1, 2].set_title('Intra Cluster Interaction Similarity')\n",
    "    ax[1, 2].set_ylabel('Jaccard Similarity')\n",
    "    \n",
    "    ax[2, 0].set_title('Diversity')\n",
    "    ax[2, 0].set_ylabel('Diversity')\n",
    "    \n",
    "    ax[2, 1].set_title('Inter Cluster Recommendation similarity')\n",
    "    ax[2, 1].set_ylabel('Jaccard Similarity')\n",
    "    \n",
    "    ax[2, 2].set_title('Intra Cluster Recommendation similarity')\n",
    "    ax[2, 2].set_ylabel('Jaccard Similarity')\n",
    "    \n",
    "    ax[3, 0].set_title('Serendipity')\n",
    "    ax[3, 0].set_ylabel('Serendipity')\n",
    "    \n",
    "    ax[3, 1].set_title('Novelty')\n",
    "    ax[3, 1].set_ylabel('Novelty')\n",
    "\n",
    "    ax[3, 2].set_title('Mean Number of Topics Interacted per User')\n",
    "    ax[3, 2].set_ylabel('Mean Number of Topics Interacted per User')\n",
    "    \n",
    "    fig.legend(legend_lines, legend_names, loc='upper center', fontsize=14, frameon=False, ncol=5, bbox_to_anchor=(.5, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_histogram\n",
      "mse\n",
      "interaction_spread\n",
      "inter_cluster_interaction_similarity\n",
      "intra_cluster_interaction_similarity\n",
      "inter_cluster_rec_similarity\n",
      "intra_cluster_rec_similarity\n",
      "user_mse\n",
      "serendipity_metric\n",
      "diversity_metric\n",
      "novelty_metric\n",
      "recall_at_k\n",
      "mean_num_topics\n",
      "timesteps\n"
     ]
    }
   ],
   "source": [
    "measurements = model.get_measurements()\n",
    "for i in measurements.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82ad1e6da8c8551612185ff57ab4e881be31b0c67a550f3cbdb2f98515f5914e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('fairRS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
