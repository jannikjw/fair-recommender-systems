{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lyzbdeoNVB7V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from importlib import reload\n",
    "from trecs.metrics import MSEMeasurement, InteractionSpread, InteractionSpread, InteractionSimilarity, RecSimilarity, RMSEMeasurement, InteractionMeasurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo\n",
    "import src.globals as globals\n",
    "import seaborn as sns\n",
    "\n",
    "from wrapper.models.bubble import BubbleBurster\n",
    "from src.utils import *\n",
    "from src.plotting import plot_measurements \n",
    "from src.scoring_functions import cosine_sim, entropy, content_fairness\n",
    "from wrapper.metrics.evaluation_metrics import *\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "globals.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RecommenderSystem on MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attrs=20\n",
    "max_iter=1000\n",
    "n_clusters=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fn = ''\n",
    "probabilistic = False\n",
    "globals.ALPHA = 0.2\n",
    "alpha = globals.ALPHA\n",
    "\n",
    "# User parameters\n",
    "drift = 0.05\n",
    "attention_exp=-0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ratings_matrix = load_and_process_movielens(file_path='data/ml-100k/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Get user and item representations using NMF\n",
    "user_representation, item_representation = create_embeddings(binary_ratings_matrix, n_attrs=n_attrs, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clusters.\n",
      "Loaded clusters.\n"
     ]
    }
   ],
   "source": [
    "# Define topic clusters using NMF\n",
    "item_cluster_ids, item_cluster_centers = get_clusters(item_representation.T, name='item', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)\n",
    "user_cluster_ids, user_cluster_centers = get_clusters(user_representation, name='user', n_clusters=n_clusters, n_attrs=n_attrs, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 20\n",
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_representation)\n",
    "num_items = len(item_representation)\n",
    "print(f'Number of items: {num_items}')\n",
    "print(f'Number of users: {num_users}')\n",
    "\n",
    "users = Users(actual_user_profiles=user_representation, \n",
    "              repeat_interactions=False, \n",
    "              drift=drift,\n",
    "              attention_exp=attention_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user_pairs by pairing users only with others that are not in the same cluster\n",
    "num_users = len(user_representation)\n",
    "inter_cluster_user_pairs = []\n",
    "for u_idx in range(num_users):\n",
    "    for v_idx in range(num_users):\n",
    "        if user_cluster_ids[u_idx] != user_cluster_ids[v_idx]:\n",
    "            inter_cluster_user_pairs.append((u_idx, v_idx))\n",
    "\n",
    "intra_cluster_user_pairs = []\n",
    "for u_idx in range(num_users):\n",
    "    for v_idx in range(num_users):\n",
    "        if user_cluster_ids[u_idx] == user_cluster_ids[v_idx]:\n",
    "            intra_cluster_user_pairs.append((u_idx, v_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSEMeasurement()\n",
    "measurements = [\n",
    "    InteractionMeasurement(),\n",
    "    MSEMeasurement(),  \n",
    "    InteractionSpread(),                \n",
    "    InteractionSimilarity(pairs=inter_cluster_user_pairs, name='inter_cluster_interaction_similarity'), \n",
    "    InteractionSimilarity(pairs=intra_cluster_user_pairs, name='intra_cluster_interaction_similarity'), \n",
    "    RecSimilarity(pairs=inter_cluster_user_pairs, name='inter_cluster_rec_similarity'), \n",
    "    RecSimilarity(pairs=intra_cluster_user_pairs, name='intra_cluster_rec_similarity'), \n",
    "    UserMSEMeasurement(),\n",
    "    SerendipityMetric(), \n",
    "    DiversityMetric(), \n",
    "    NoveltyMetric(),\n",
    "    RecallMeasurement(),\n",
    "    MeanNumberOfTopics(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "config = {\n",
    "    'actual_user_representation': users,\n",
    "    'actual_item_representation': item_representation,\n",
    "    'item_topics': item_cluster_ids,\n",
    "    'num_attributes': n_attrs,\n",
    "    'num_items_per_iter': 10,\n",
    "    'seed': 42,\n",
    "    'record_base_state': True,\n",
    "}\n",
    "\n",
    "model_name='myopic'\n",
    "requires_alpha = False\n",
    "\n",
    "if score_fn:\n",
    "    if score_fn == 'cosine_sim':\n",
    "        config['score_fn'] = cosine_sim\n",
    "        requires_alpha = True\n",
    "    elif score_fn == 'entropy':\n",
    "        config['score_fn'] = entropy\n",
    "        requires_alpha = True\n",
    "    elif score_fn == 'content_fairness':\n",
    "        config['score_fn'] = content_fairness        \n",
    "    else:\n",
    "        raise Exception('Given score function does not exist.')\n",
    "    model_name = score_fn\n",
    "\n",
    "if probabilistic:\n",
    "    config['probabilistic_recommendations'] = True\n",
    "    model_name += '_prob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BubbleBurster(**config)\n",
    "\n",
    "model.add_metrics(*measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVSpo-18VHH4",
    "outputId": "cef8814a-7ccb-4da1-dae9-aab8fdcad51d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:46<00:00,  9.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fair Model\n",
    "train_timesteps=5\n",
    "model.startup_and_train(timesteps=train_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 4/20 [00:49<03:20, 12.52s/it]"
     ]
    }
   ],
   "source": [
    "run_timesteps=20\n",
    "model.run(timesteps=run_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zbOWgfvksMs4",
    "outputId": "c770281b-05e6-4b3c-c79c-91809cd5f76a"
   },
   "outputs": [],
   "source": [
    "import src\n",
    "reload(src.utils)\n",
    "from src.utils import *\n",
    "    \n",
    "# Determine file name based on parameter values\n",
    "parameters = f'_{train_timesteps}trainTimesteps_{run_timesteps}runTimesteps_{n_attrs}nAttrs_{n_clusters}nClusters_{drift}Drift_{attention_exp}AttentionExp'\n",
    "if requires_alpha:\n",
    "    parameters += f'_{alpha}Lambda'\n",
    "\n",
    "# Save actual user preferences\n",
    "final_preferences_dir = 'artefacts/final_preferences/'\n",
    "file_prefix = f'{model_name}_final_preferences'\n",
    "final_preferences_path = final_preferences_dir + file_prefix + parameters + '.npy'\n",
    "np.save(final_preferences_path, model.users.actual_user_profiles.value, allow_pickle=True)\n",
    "\n",
    "# Save measurements\n",
    "measurements_dir = f'artefacts/measurements/'\n",
    "file_prefix = f'{model_name}_measurements'\n",
    "\n",
    "measurements_path = measurements_dir + file_prefix + parameters + '.csv'\n",
    "measurements_df = load_or_create_measurements_df(model, model_name, train_timesteps, measurements_path)\n",
    "measurements_df.to_csv(measurements_path)\n",
    "print('Measurements saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zbOWgfvksMs4",
    "outputId": "c770281b-05e6-4b3c-c79c-91809cd5f76a"
   },
   "outputs": [],
   "source": [
    "# Create df for parameters\n",
    "numeric_cols = ['trainTimesteps', 'runTimesteps', 'nAttrs', 'nClusters', 'Lambda']\n",
    "columns = ['model_name'] + numeric_cols\n",
    "\n",
    "data = [[model_name, train_timesteps, run_timesteps, n_attrs, n_clusters, None]]\n",
    "if requires_alpha:\n",
    "    data = [[model_name, train_timesteps, run_timesteps, n_attrs, n_clusters, alpha]]\n",
    "\n",
    "parameters_df = pd.DataFrame(data,\n",
    "                             columns = columns)\n",
    "for col in numeric_cols:\n",
    "    parameters_df[col] = pd.to_numeric(parameters_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zbOWgfvksMs4",
    "outputId": "c770281b-05e6-4b3c-c79c-91809cd5f76a"
   },
   "outputs": [],
   "source": [
    "plot_measurements([measurements_df], parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novelty that is based on probability calculation from generate_recommendations \n",
    "# (leave previously interacted items out)\n",
    "item_counts = recommender.item_count\n",
    "item_counts[item_counts == 0] = 1\n",
    "items_self_info = (-1) * np.log(item_counts)\n",
    "\n",
    "# turn scores in probability distribution over items to ensure that all independent of the ranking function, the metric yields comparable values\n",
    "scores = recommender.predicted_scores.value\n",
    "probabilities = scores / np.sum(scores, axis=1)[:, np.newaxis]\n",
    "\n",
    "item_indices = recommender.indices\n",
    "if not recommender.users.repeat_interactions:\n",
    "    # for each user, eliminate items that have been interacted with\n",
    "    item_indices = item_indices[np.where(item_indices >= 0)]\n",
    "    item_indices = item_indices.reshape((recommender.num_users, -1))\n",
    "\n",
    "s_filtered = mo.to_dense(recommender.predicted_scores.filter_by_index(item_indices))\n",
    "row = np.repeat(recommender.users.user_vector, item_indices.shape[1])\n",
    "row = row.reshape((recommender.num_users, -1))\n",
    "permutation = s_filtered.argsort()\n",
    "rec = item_indices[row, permutation]\n",
    "# the recommended items will not be exactly determined by\n",
    "# predicted score; instead, we will sample from the sorted list\n",
    "# such that higher-preference items get more probability mass\n",
    "num_items_unseen = rec.shape[1]  # number of items unseen per user\n",
    "probabilities = np.logspace(0.0, num_items_unseen / 10.0, num=num_items_unseen, base=2)\n",
    "probabilities = probabilities / probabilities.sum()\n",
    "\n",
    "# get utility of each item given a state of users\n",
    "item_states = np.mean(probabilities, axis=0)\n",
    "\n",
    "# calculate novelty per item by multiplying self information and utility value\n",
    "item_novelties = items_self_info * item_states\n",
    "# form sum over all possible items/actions\n",
    "item_novelty = np.sum(item_novelties)\n",
    "\n",
    "item_novelty"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "rsenv2",
   "language": "python",
   "name": "rsenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c64b5f0e204e2b557bfa409cf6c0678c4f1eefdf2bd314df48e0edc57cda315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
